{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 969
    },
    "colab_type": "code",
    "id": "d3AXtK7Dfff7",
    "outputId": "72027a53-b334-411c-f335-7db734bcac89"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 96)        2688      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 192)       166080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12288)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               3145984   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 3,317,322\n",
      "Trainable params: 3,317,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.3885 - accuracy: 0.5037\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 0.9869 - accuracy: 0.6541\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 0.8344 - accuracy: 0.7080\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 0.7237 - accuracy: 0.7460\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 7s 130us/step - loss: 0.6220 - accuracy: 0.7808\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 0.5414 - accuracy: 0.8099\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 0.4480 - accuracy: 0.8423\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 0.3704 - accuracy: 0.8703\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 0.2979 - accuracy: 0.8962\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 0.2349 - accuracy: 0.9190\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 0.1857 - accuracy: 0.9366\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.1483 - accuracy: 0.9489\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 0.1259 - accuracy: 0.9561\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 0.1001 - accuracy: 0.9656\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 0.1065 - accuracy: 0.9625\n",
      "10000/10000 [==============================] - 1s 112us/step\n",
      "Loss: 1.6886400791168212\n",
      "Accuracy: 0.7123000025749207\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.utils import np_utils, plot_model\n",
    "from keras.datasets import cifar10\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as tfback\n",
    "def _get_available_gpus():\n",
    "    \"\"\"Get a list of available gpu devices (formatted as strings).\n",
    "\n",
    "    # Returns\n",
    "        A list of available GPU devices.\n",
    "    \"\"\"\n",
    "    #global _LOCAL_DEVICES\n",
    "    if tfback._LOCAL_DEVICES is None:\n",
    "        devices = tf.config.list_logical_devices()\n",
    "        tfback._LOCAL_DEVICES = [x.name for x in devices]\n",
    "    return [x for x in tfback._LOCAL_DEVICES if 'device:gpu' in x.lower()]\n",
    "\n",
    "tfback._get_available_gpus = _get_available_gpus\n",
    "\n",
    "# Cifar10 Dataset\n",
    "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
    "# print(x_test.shape)\n",
    "x_train = X_train.reshape(50000, 32, 32, 3)/255\n",
    "x_test = X_test.reshape(10000, 32, 32, 3)/255\n",
    "y_train = np_utils.to_categorical(Y_train)\n",
    "y_test = np_utils.to_categorical(Y_test)\n",
    "\n",
    "\n",
    "# Model Structure\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=96, kernel_size=3, input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPool2D(pool_size=2))\n",
    "model.add(Conv2D(filters=192, kernel_size=3, input_shape=(64, 16, 16), activation='relu', padding='same'))\n",
    "model.add(MaxPool2D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=15, batch_size=64, verbose=1)\n",
    "# Test the model\n",
    "\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print('Loss: %s\\nAccuracy: %s' % (loss, accuracy))\n",
    "\n",
    "# Save model\n",
    "model.save('./CNN_Cifar10.h5')\n",
    "\n",
    "# Load Model\n",
    "model_next = load_model('./CNN_Cifar10.h5')\n",
    "\n",
    "\n",
    "# # Display\n",
    "# def plot_img(n):\n",
    "#     plt.imshow(X_test[n], cmap='gray')\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# def all_img_predict(model):\n",
    "#     print(model.summary())\n",
    "#     loss, accuracy = model.evaluate(x_test, y_test)\n",
    "#     print('Loss:', loss)\n",
    "#     print('Accuracy:', accuracy)\n",
    "#     predict = model.predict_classes(x_test)\n",
    "#     print(pd.crosstab(Y_test.reshape(-1), predict, rownames=['Label'], colnames=['predict']))\n",
    "\n",
    "\n",
    "# def one_img_predict(model, n):\n",
    "#     predict = model.predict_classes(x_test)\n",
    "#     print('Prediction:', predict[n])\n",
    "#     print('Answer:', Y_test[n])\n",
    "#     plot_img(n)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "b07901146_cifar10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
